{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['app_id', 'app_name', 'review_text', 'review_score', 'review_votes'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(r\"D:\\PHUCHUY\\THUC_HANH\\dataset.csv\\dataset.csv\")  # Đặt 'r' trước đường dẫn để tránh lỗi escape characters\n",
    "print(df.columns)  # Xem danh sách cột\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\phuy7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\phuy7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\phuy7\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Cài đặt các thư viện cần thiết\n",
    "import re\n",
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Tải dữ liệu NLP cần thiết\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Danh sách từ sentiment theo rule-based\n",
    "positive_words = {\"good\", \"great\", \"excellent\", \"amazing\", \"fantastic\", \"love\", \"wonderful\", \"best\", \"awesome\", \"happy\"}\n",
    "negative_words = {\"bad\", \"terrible\", \"awful\", \"worst\", \"hate\", \"poor\", \"horrible\", \"disappointed\", \"sad\", \"annoying\"}\n",
    "\n",
    "# Hàm tiền xử lý văn bản\n",
    "def preprocess_text(text):\n",
    "    text = str(text).lower()  # Chuyển về chữ thường\n",
    "    text = re.sub(r'[^a-zA-Z ]', '', text)  # Loại bỏ ký tự không phải chữ cái\n",
    "    words = word_tokenize(text)  # Tách từ\n",
    "    words = [w for w in words if w not in stopwords.words('english')]  # Bỏ stopwords\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(w) for w in words]  # Lemmatization\n",
    "    return \" \".join(words)\n",
    "\n",
    "# Hàm phân loại sentiment theo rule-based\n",
    "def rule_based_sentiment(text):\n",
    "    words = set(word_tokenize(text.lower()))\n",
    "    pos_count = len(words & positive_words)\n",
    "    neg_count = len(words & negative_words)\n",
    "    if pos_count > neg_count:\n",
    "        return \"positive\"\n",
    "    elif neg_count > pos_count:\n",
    "        return \"negative\"\n",
    "    else:\n",
    "        return \"neutral\"\n",
    "\n",
    "# Đọc dữ liệu từ file CSV\n",
    "df = pd.read_csv(r\"D:\\PHUCHUY\\THUC_HANH\\dataset.csv\\dataset.csv\", encoding=\"utf-8\")\n",
    "\n",
    "# Kiểm tra cột có sẵn\n",
    "print(\"Các cột trong file CSV:\", df.columns)\n",
    "\n",
    "# Kiểm tra xem cột 'review_text' có tồn tại không\n",
    "if 'review_text' not in df.columns or 'review_score' not in df.columns:\n",
    "    raise KeyError(\"File CSV phải có cột 'review_text' và 'review_score'. Kiểm tra lại dữ liệu!\")\n",
    "\n",
    "# Áp dụng tiền xử lý và rule-based sentiment\n",
    "df['cleaned_review'] = df['review_text'].apply(preprocess_text)\n",
    "df['rule_sentiment'] = df['cleaned_review'].apply(rule_based_sentiment)\n",
    "\n",
    "# Chia tập dữ liệu train-test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['cleaned_review'], df['review_score'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Mô hình Machine Learning (RandomForest)\n",
    "pipeline = Pipeline([\n",
    "    ('vectorizer', CountVectorizer()),   # Chuyển văn bản thành vector đếm từ\n",
    "    ('tfidf', TfidfTransformer()),       # Chuyển thành trọng số TF-IDF\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))  # Mô hình RF\n",
    "])\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred_ml = pipeline.predict(X_test)\n",
    "\n",
    "# So sánh với rule-based\n",
    "y_pred_rule = df.loc[X_test.index, 'rule_sentiment']\n",
    "\n",
    "# Kết hợp Rule-based + ML (Voting)\n",
    "def hybrid_sentiment(rule_label, ml_label):\n",
    "    if rule_label != \"neutral\":  # Nếu rule-based đưa ra kết quả rõ ràng thì giữ nguyên\n",
    "        return rule_label\n",
    "    return ml_label  # Nếu rule-based là 'neutral', dùng ML\n",
    "\n",
    "df.loc[X_test.index, 'hybrid_sentiment'] = [hybrid_sentiment(r, m) for r, m in zip(y_pred_rule, y_pred_ml)]\n",
    "\n",
    "# Đánh giá kết quả\n",
    "print(\"\\n=== Đánh giá mô hình ===\")\n",
    "print(\"Machine Learning Accuracy:\", accuracy_score(y_test, y_pred_ml))\n",
    "print(\"Rule-based Accuracy:\", accuracy_score(y_test, y_pred_rule))\n",
    "print(\"Hybrid Accuracy:\", accuracy_score(y_test, df.loc[X_test.index, 'hybrid_sentiment']))\n",
    "print(\"\\nClassification Report (Hybrid Model):\")\n",
    "print(classification_report(y_test, df.loc[X_test.index, 'hybrid_sentiment']))\n",
    "\n",
    "# Xuất kết quả ra file CSV\n",
    "df.to_csv(\"sentiment_results.csv\", index=False)\n",
    "print(\"Kết quả đã được lưu vào sentiment_results.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
